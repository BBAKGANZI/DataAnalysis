{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "14_뉴스그룹_분류.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nGJTRyQ1RUO"
      },
      "source": [
        "# Top 20 뉴스그룹 분류"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME9wdZ031GLG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0J3fFj6n2FVP",
        "outputId": "da038834-0ef0-4676-a873-baee14820e76"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "news = fetch_20newsgroups(subset='all', random_state=2021)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9KhR_sG259q"
      },
      "source": [
        "## 데이터 탐색"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju3tmq9022uX",
        "outputId": "91977392-05a4-452e-cfff-3a188dbe9531"
      },
      "source": [
        "news.keys()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpNtuDOm3Tk9",
        "outputId": "1e7ad733-05fa-41bb-ea52-3b3a16956ab2"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "iris.keys()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xetxRUDE3aV_",
        "outputId": "bf159b6b-a227-4f17-fadd-a55271e7239c"
      },
      "source": [
        "news.target_names"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYb9XIHd4OBr",
        "outputId": "9aefa4a1-6cc7-48b1-fd1f-24a6b354b61e"
      },
      "source": [
        "pd.Series(news.target).value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10    999\n",
              "15    997\n",
              "8     996\n",
              "9     994\n",
              "11    991\n",
              "13    990\n",
              "7     990\n",
              "5     988\n",
              "14    987\n",
              "2     985\n",
              "12    984\n",
              "3     982\n",
              "6     975\n",
              "1     973\n",
              "4     963\n",
              "17    940\n",
              "16    910\n",
              "0     799\n",
              "18    775\n",
              "19    628\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUEl7Y6X4iLo",
        "outputId": "56b56997-3995-4f4e-ad6f-aa68d67cbe60"
      },
      "source": [
        "pd.Series(news.target).value_counts().sort_index()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     799\n",
              "1     973\n",
              "2     985\n",
              "3     982\n",
              "4     963\n",
              "5     988\n",
              "6     975\n",
              "7     990\n",
              "8     996\n",
              "9     994\n",
              "10    999\n",
              "11    991\n",
              "12    984\n",
              "13    990\n",
              "14    987\n",
              "15    997\n",
              "16    910\n",
              "17    940\n",
              "18    775\n",
              "19    628\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTUielN64rLZ",
        "outputId": "bcb1bfa3-cb8a-4a1c-9448-9b6cf14b56e4"
      },
      "source": [
        "len(news.data)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18846"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MFK-OEw5JiV",
        "outputId": "2a53c444-0768-445b-a890-d605275df04d"
      },
      "source": [
        "print(news.data[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: dagibbs@quantum.qnx.com (David Gibbs)\n",
            "Subject: Re: Countersteering sans Hands\n",
            "Organization: QNX Software Systems, Ltd.\n",
            "Lines: 22\n",
            "\n",
            "In article <1993Apr20.203344.8417@cs.cornell.edu> karr@cs.cornell.edu (David Karr) writes:\n",
            ">In article <Clarke.6.735328328@bdrc.bd.com> Clarke@bdrc.bd.com (Richard Clarke) writes:\n",
            ">>So how do I steer when my hands aren't on the bars? (Open Budweiser in left \n",
            ">>hand, Camel cigarette in the right, no feet allowed.) \n",
            ">\n",
            ">>If I lean, and the \n",
            ">>bike turns, am I countersteering?\n",
            ">\n",
            ">No, the bars would turn only *toward* the direction of turn in\n",
            ">no-hands steering.\n",
            "\n",
            "Just in case the original poster was looking for a serious answer,\n",
            "I'll supply one.\n",
            "\n",
            "Yes, even when steering no hands you do something quite similar\n",
            "to countersteering.  Basically to turn left, you to a quick wiggle\n",
            "of the bike to the right first, causing a counteracting lean to\n",
            "occur to the left.  It is a lot more difficult to do on a motorcycle\n",
            "than a bicycle though, because of the extra weight.  (Ok, so my\n",
            "motorcycle is heavy.  Maybe yous isn't.)\n",
            "\n",
            "-David\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2Iud-7z5mrW"
      },
      "source": [
        "## 훈련/테스트용 데이터 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YCxd7Qr5Lwd",
        "outputId": "2566cbf1-0f56-45be-85f3-13e0822f3f05"
      },
      "source": [
        "train_news = fetch_20newsgroups(\n",
        "    subset = 'train', random_state = 2021, remove = ('headers', 'footers', 'quotes')\n",
        ")\n",
        "len(train_news.data)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11314"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxiEHxZe6Hm_",
        "outputId": "e409e32c-613b-453d-81d5-d9f09fb2f48f"
      },
      "source": [
        "test_news = fetch_20newsgroups(\n",
        "    subset = 'test', random_state = 2021, remove = ('headers', 'footers', 'quotes')\n",
        ")\n",
        "len(test_news.data)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7532"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjXWhqn-6f20",
        "outputId": "1ebb2fd1-d9f7-43a6-c6d3-57ccdf8dff79"
      },
      "source": [
        "print(train_news.data[1])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "]Is it possible to do a \"wheelie\" on a motorcycle with shaft-drive?\n",
            "\n",
            "yes.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QxtXF9w84vP",
        "outputId": "07e11371-e645-4d2f-93e2-797355e4b84e"
      },
      "source": [
        "print(test_news.data[0])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Need Diet for Diverticular Disease\n",
            "and ideas for gastrointestinal distress\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKQq7Nes6pW_"
      },
      "source": [
        "## 텍스트 데이터에 대해서 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTxFjdxX6kWN"
      },
      "source": [
        "train_df = pd.DataFrame({'article': train_news.data})\n",
        "test_df = pd.DataFrame({'article': test_news.data})"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeYUzwDO9Myb"
      },
      "source": [
        "- Train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qbepT81M7UYU",
        "outputId": "98b2f9a0-abba-4ebe-9c14-3dd9c5244229"
      },
      "source": [
        "# 특수문자 제거\n",
        "train_df['article'] = train_df.article.str.replace('[^A-Za-z]', ' ')\n",
        "train_df.article[1]\n",
        "# train_df['article'] = train_df['article'].astype(str).apply(lambda x : re.sub('r[^A-Za-z ]', '', x))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Is it possible to do a  wheelie  on a motorcycle with shaft drive   yes  '"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WyBayMID9GJN",
        "outputId": "f2612f1b-3f5a-4205-9b7a-40c276efd8a2"
      },
      "source": [
        "# 길이가 3 이하인 단어 제거\n",
        "train_df['article'] = train_df.article.apply(lambda x: ' '.join([w for w in x.split() if len(w) > 3]))\n",
        "train_df.article[1]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'possible wheelie motorcycle with shaft drive'"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "B1DZNK6JB0L1",
        "outputId": "f8736716-223f-4fdb-e700-8f22159d1f9c"
      },
      "source": [
        "s = 'a ab abc abcd abcde'\n",
        "x = []\n",
        "for w in s.split():\n",
        "    if len(w) > 3:\n",
        "        x.append(w)\n",
        "s = ' '.join([w for w in s.split() if len(w) > 3])\n",
        "s"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'abcd abcde'"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "R5o_HF5RCPW9",
        "outputId": "64463df9-cb21-4084-9d46-4e566bc83cc6"
      },
      "source": [
        "# 소문자로 변환\n",
        "train_df['article'] = train_df.article.apply(lambda x: x.lower())\n",
        "train_df.article[0]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'stop hold have problems here official history says that first accusations homosexuality came from outside nazi party long before nazis ever came power this objection herring even established history wrong this point moreover none histories read ever made mention hitler anyone else ever using homosexuality pretext purging roehm point reiterated that hitler party covered these accusations going accuse official history being fabrication should least your facts right pretext purging roehm that planning coup against hitler nowhere there mention using allegations homosexuality pretext purge justification afterwards possible that histories read have mentioned this doubt would hitler best interest admit world that former right hand homosexual anyway said before always possible that have missed references nazis making charges homosexuality against after night long knives this does prove that they were false even nazis could tell truth when their advantage case this does deal with accusations homosexuality during forgot this being posted conspiracy smell paranoia from here since nazis never officially charged roehm with homosexuality least according what read like know what tainted evidence talking about since accusations were made persons outside nazi party long before came power those accusations were common knowledge journalists others germany just would possible nazis back time plant tainted evidence exactly does doctor newspapers which were circulated around world without discrepancies being obvious what actual incidences nazi doctoring evidence this matter know about what about testimony people were involved these matters some whom were nazis what point making false accusation homosexuality publicize since point here seems discredit established history then burden proof falls revisionist revisionists better their homework before making accusations otherwise they simply look like conspiracy nuts this just about only thing agree suspect that notion that there might have been people roehm buddies were homosexuals must disturb some people feeling seems that nasty individual accused homosexuality that this must attempt bash homosexuals this fear often justified what lies behind this distrust official history seems this good justification trashing accepted accounts this subject really think that historians incompetent write them where they their sources this subject tell from their footnotes graduate student history writing professors tracking down sources time limited this specialty neither anyone else have said anything that would cast shred doubt existing evidence going waste time trying debunk someone paranoia research yourself given that already consider evidence tainted what earth would constitute concrete particulars since when have concrete particulars been considered shrewd guesses suggest that those trust popular historians irving historians writing popular audience rule provide copious footnotes should instead reading academic historians usually provide footnotes their sources immmense detail this place start looking assuming that really wants know truth folks pagan tired this subject already apologies seem have gone tangent forget which gods responsible keeping strings within appropriate newsgroup subject boundaries'"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjZSWyNaDN9A"
      },
      "source": [
        "# 소문자로 변환하고 길이가 3 이하인 단어 제거\n",
        "train_df['article'] = train_df.article.apply(lambda x: ' '.join([w.lower() for w in x.split() if len(w) > 3]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-NOkYmDDwXl"
      },
      "source": [
        "- Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "hRP6js9XDmxa",
        "outputId": "fea0deb4-6928-4df8-84e4-40d9146f7dc8"
      },
      "source": [
        "# 특수문자 제거\n",
        "test_df['article'] = test_df.article.str.replace('[^A-Za-z]', ' ')\n",
        "# 소문자로 변환하고 길이가 3 이하인 단어 제거\n",
        "test_df['article'] = test_df.article.apply(lambda x: ' '.join([w.lower() for w in x.split() if len(w) > 3]))\n",
        "test_df.article[1]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'there chips which perform voice compression expansion they expensive because they exist many phones connected pbxs line cards well equipment which compresses voice grade circuits save cost long distance leased satellite circuits remember generic term these chips impression that this deal years circuits have gotten cheap that done much'"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PneVLNC1ENyd"
      },
      "source": [
        "## 텍스트 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nyvzn4P-EHtw"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZNebcDeEY7b",
        "outputId": "81b2f20e-7148-4e38-9d98-a8295140a3ad"
      },
      "source": [
        "tvect = TfidfVectorizer(stop_words='english')\n",
        "tvect.fit(train_df.article)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
              "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words='english', strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2t2i_BnE1im",
        "outputId": "b92629f4-d802-4ebb-87a1-92628207b32a"
      },
      "source": [
        "X_train = tvect.transform(train_df.article)\n",
        "X_test = tvect.transform(test_df.article)\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11314, 64133), (7532, 64133))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMUCerRnFHF6"
      },
      "source": [
        "y_train = train_news.target\n",
        "y_test = test_news.target"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvMMIqt-Flku"
      },
      "source": [
        "## 훈련/예측/평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVXGAwjNFWP-",
        "outputId": "8526940f-6b50-497a-ce08-0b4db0ca8c9f"
      },
      "source": [
        "# Support Vector Machine의 Classifier 사용\n",
        "from sklearn.svm import SVC\n",
        "svc = SVC()\n",
        "svc.fit(X_train, y_train)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpC6eapmF5jE"
      },
      "source": [
        "pred = svc.predict(X_test)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhfibkGuGkgR",
        "outputId": "2f5ffa62-f20d-4d80-e1bc-76652abbc125"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, pred)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6488316516197558"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpSJRiMDGu-l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}